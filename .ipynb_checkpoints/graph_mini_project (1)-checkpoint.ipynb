{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf8a1cf6",
   "metadata": {},
   "source": [
    "#### GRAPH MINI PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7d8d6",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a550d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18648ea6",
   "metadata": {},
   "source": [
    "### Obtain datasets\n",
    "\n",
    "* **Dataset 1**: social circles in Facebook.\n",
    "    * 10 ego networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb8b994",
   "metadata": {},
   "source": [
    "##### (1) Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fcaf235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://snap.stanford.edu/data/facebook.tar.gz'\n",
    "# response = requests.get(url)\n",
    "\n",
    "# with open('facebook.tar.gz', 'wb') as f:\n",
    "#     f.write(response.content)\n",
    "\n",
    "\n",
    "# url = https://string-db.org/cgi/download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf33d81",
   "metadata": {},
   "source": [
    "##### (2) Extract data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d5abbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4v/h6s7ydv146g9ctj5pb52h3740000gn/T/ipykernel_15579/671836949.py:2: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path='facebook_data')  # Extract files into folder 'facebook_data'\n"
     ]
    }
   ],
   "source": [
    "with tarfile.open('facebook.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall(path='facebook_data')  # Extract files into folder 'facebook_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986b1a3",
   "metadata": {},
   "source": [
    "##### (3) Check extracted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f17467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['facebook']\n"
     ]
    }
   ],
   "source": [
    "extracted_files = os.listdir('facebook_data')\n",
    "print(extracted_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69879c56",
   "metadata": {},
   "source": [
    "##### (4) Load all ego networks (graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd9cb491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing Facebook ego networks:\n",
    "dataset_path = 'facebook_data/facebook'\n",
    "# List of ego node IDs (from the file names):\n",
    "ego_node_ids = ['0', '107', '348', '414', '686', '698', '1684', '1912', '3437', '3980']\n",
    "# Function to load one ego network:\n",
    "def load_ego_network(node_id):\n",
    "    # we get the edges file for the corresponding ego network\n",
    "    edge_file = os.path.join(dataset_path, f\"{node_id}.edges\")\n",
    "    G = nx.Graph()\n",
    "    # we read the edges file and add edges to the graph\n",
    "    with open(edge_file, 'r') as f:\n",
    "        for line in f:\n",
    "            edge = line.strip().split()\n",
    "            G.add_edge(edge[0], edge[1])\n",
    "    neighbors = set(G.nodes())\n",
    "    G.add_node(node_id) # we add the ego node to the graph\n",
    "    for neighbor in neighbors: # we assume all nodes in the edges file are direct neighbors of the ego node\n",
    "        G.add_edge(node_id, neighbor) # we connect the ego node to its neighbors\n",
    "    return G\n",
    "\n",
    "\n",
    "def analyze_network(G, ego_id):\n",
    "    # Calculate centrality metrics:\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    closeness_centrality = nx.closeness_centrality(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    clustering_coefficient = nx.clustering(G)\n",
    "\n",
    "    # Print network summary\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Ego Network {ego_id} Statistics and centrality metrics:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "    print(f\"Density: {nx.density(G):.4f}\\n\")\n",
    "    # print(f\"Graph degree centrality: {degree_centrality}\")\n",
    "    # print(f\"Graph closeness centrality: {closeness_centrality}\")\n",
    "    # print(f\"Graph betweenness centrality: {betweenness_centrality}\")\n",
    "    # print(f\"Graph clustering coefficient: {clustering_coefficient}\")\n",
    "    \n",
    "    # Create a DataFrame to summarize metrics of each node\n",
    "    df_graph_metrics = pd.DataFrame({\n",
    "        # 'Number of nodes': G.number_of_nodes(),\n",
    "        # 'Number of edges': G.number_of_edges(),\n",
    "        # 'Density': nx.density(G):.4f,\n",
    "        'Node': list(G.nodes()),\n",
    "        'Degree centrality': [degree_centrality[n] for n in G.nodes()],\n",
    "        'Closeness centrality': [closeness_centrality[n] for n in G.nodes()],\n",
    "        'Betweenness centrality': [betweenness_centrality[n] for n in G.nodes()],\n",
    "        'Clustering coefficient': [clustering_coefficient[n] for n in G.nodes()]\n",
    "    })\n",
    "    df_graph_metrics = df_graph_metrics.set_index('Node')\n",
    "    print(\"=\"*70)\n",
    "    print(\"Node-level metrics:\")\n",
    "    print(\"=\"*70)\n",
    "    # print(df_graph_metrics.head(20))\n",
    "    # Extract top 5 nodes and corresponding values for each metric\n",
    "    top_nodes = {}\n",
    "    for metric in df_graph_metrics.columns:\n",
    "        top = df_graph_metrics[metric].nlargest(5)\n",
    "        top_nodes[metric] = top\n",
    "    print(\"\\nTop 5 nodes per metric:\")\n",
    "    # Create a summary table where each metric has two columns: top node IDs and their values\n",
    "    summary_df = pd.DataFrame()\n",
    "\n",
    "    for metric, top in top_nodes.items():\n",
    "        # Column with top node IDs\n",
    "        summary_df[f\"{metric}_nodes\"] = pd.Series(top.index).reset_index(drop=True)\n",
    "        # Column with the corresponding top values\n",
    "        summary_df[f\"{metric}_values\"] = pd.Series(top.values).reset_index(drop=True)\n",
    "\n",
    "    print(summary_df)\n",
    "    \n",
    "    # # Centrality distribution plots\n",
    "    # centralities_df = pd.DataFrame({\n",
    "    #     'degree': list(degree_centrality.values()),\n",
    "    #     'closeness': list(closeness_centrality.values()),\n",
    "    #     'betweenness': list(betweenness_centrality.values())\n",
    "    # })\n",
    "    \n",
    "    # plt.figure(figsize=(12, 4))\n",
    "    # for i, metric in enumerate(centralities_df.columns):\n",
    "    #     plt.subplot(1, 3, i+1)\n",
    "    #     sns.histplot(centralities_df[metric], bins=20, kde=True)\n",
    "    #     plt.title(f\"{metric.capitalize()} Centrality Distribution\")\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "def plot_network(G, ego_id):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, node_size=50, font_size=8)\n",
    "    plt.title(f\"Ego Network {ego_id}\")\n",
    "    plt.show()\n",
    "\n",
    "# Load all ego networks and visualize them:\n",
    "for ego_id in ego_node_ids:\n",
    "    G = load_ego_network(ego_id)\n",
    "    analyze_network(G, ego_id)\n",
    "    plot_network(G, ego_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protein_section",
   "metadata": {},
   "source": [
    "### Protein-Protein Interaction Network Analysis\n",
    "\n",
    "* **Dataset 2**: Protein-protein interaction network from STRING database.\n",
    "    * Human protein interactions (Homo sapiens - taxonomy 9606)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protein_load",
   "metadata": {},
   "source": [
    "##### (1) Load protein interaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protein_load_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the protein interaction data from the gzipped CSV file\n",
    "protein_file = '9606_protein_links_v12_0_min400_onlyAB_csv.gz'\n",
    "\n",
    "# Read the gzipped CSV file\n",
    "protein_df = pd.read_csv(protein_file, compression='gzip')\n",
    "\n",
    "print(\"Protein interaction data loaded successfully!\")\n",
    "print(f\"\\nDataset shape: {protein_df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(protein_df.head(10))\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(protein_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protein_build_graph",
   "metadata": {},
   "source": [
    "##### (2) Build protein interaction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protein_build_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_protein_network(df, min_score=400):\n",
    "    \"\"\"\n",
    "    Load protein interaction network from dataframe\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with columns 'protein1', 'protein2', 'combined_score'\n",
    "    - min_score: minimum combined score to include edge (default 400)\n",
    "    \"\"\"\n",
    "    # Filter by minimum score\n",
    "    df_filtered = df[df['combined_score'] >= min_score].copy()\n",
    "    \n",
    "    # Create weighted graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add edges with weights\n",
    "    for _, row in df_filtered.iterrows():\n",
    "        G.add_edge(row['protein1'], row['protein2'], weight=row['combined_score'])\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Build the full protein network\n",
    "protein_network = load_protein_network(protein_df, min_score=400)\n",
    "\n",
    "print(f\"Protein network created successfully!\")\n",
    "print(f\"Number of proteins (nodes): {protein_network.number_of_nodes()}\")\n",
    "print(f\"Number of interactions (edges): {protein_network.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protein_analyze",
   "metadata": {},
   "source": [
    "##### (3) Analyze protein network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protein_analyze_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_protein_network(G, network_name=\"Protein Network\"):\n",
    "    \"\"\"\n",
    "    Analyze protein interaction network using similar metrics as Facebook analysis\n",
    "    \"\"\"\n",
    "    # Calculate centrality metrics\n",
    "    print(\"Calculating degree centrality...\")\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    \n",
    "    print(\"Calculating closeness centrality...\")\n",
    "    # For large networks, closeness can be slow. Use largest connected component\n",
    "    largest_cc = max(nx.connected_components(G), key=len)\n",
    "    G_connected = G.subgraph(largest_cc).copy()\n",
    "    closeness_centrality = nx.closeness_centrality(G_connected)\n",
    "    \n",
    "    print(\"Calculating betweenness centrality...\")\n",
    "    # Sample for betweenness if graph is too large\n",
    "    if G_connected.number_of_nodes() > 5000:\n",
    "        betweenness_centrality = nx.betweenness_centrality(G_connected, k=min(1000, G_connected.number_of_nodes()))\n",
    "    else:\n",
    "        betweenness_centrality = nx.betweenness_centrality(G_connected)\n",
    "    \n",
    "    print(\"Calculating clustering coefficient...\")\n",
    "    clustering_coefficient = nx.clustering(G)\n",
    "\n",
    "    # Print network summary\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{network_name} Statistics and centrality metrics:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Number of proteins (nodes): {G.number_of_nodes()}\")\n",
    "    print(f\"Number of interactions (edges): {G.number_of_edges()}\")\n",
    "    print(f\"Density: {nx.density(G):.6f}\")\n",
    "    print(f\"Number of connected components: {nx.number_connected_components(G)}\")\n",
    "    print(f\"Size of largest connected component: {len(largest_cc)}\")\n",
    "    print(f\"Average clustering coefficient: {nx.average_clustering(G):.4f}\\n\")\n",
    "    \n",
    "    # Create a DataFrame to summarize metrics of each node\n",
    "    # Only include nodes in the connected component for closeness and betweenness\n",
    "    all_nodes = list(G.nodes())\n",
    "    \n",
    "    df_graph_metrics = pd.DataFrame({\n",
    "        'Protein': all_nodes,\n",
    "        'Degree centrality': [degree_centrality.get(n, 0) for n in all_nodes],\n",
    "        'Closeness centrality': [closeness_centrality.get(n, 0) for n in all_nodes],\n",
    "        'Betweenness centrality': [betweenness_centrality.get(n, 0) for n in all_nodes],\n",
    "        'Clustering coefficient': [clustering_coefficient.get(n, 0) for n in all_nodes]\n",
    "    })\n",
    "    df_graph_metrics = df_graph_metrics.set_index('Protein')\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"Node-level metrics:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Extract top 5 proteins and corresponding values for each metric\n",
    "    top_proteins = {}\n",
    "    for metric in df_graph_metrics.columns:\n",
    "        top = df_graph_metrics[metric].nlargest(5)\n",
    "        top_proteins[metric] = top\n",
    "    \n",
    "    print(\"\\nTop 5 proteins per metric:\")\n",
    "    # Create a summary table where each metric has two columns: top protein IDs and their values\n",
    "    summary_df = pd.DataFrame()\n",
    "\n",
    "    for metric, top in top_proteins.items():\n",
    "        # Column with top protein IDs\n",
    "        summary_df[f\"{metric}_proteins\"] = pd.Series(top.index).reset_index(drop=True)\n",
    "        # Column with the corresponding top values\n",
    "        summary_df[f\"{metric}_values\"] = pd.Series(top.values).reset_index(drop=True)\n",
    "\n",
    "    print(summary_df)\n",
    "    \n",
    "    return df_graph_metrics\n",
    "\n",
    "# Analyze the protein network\n",
    "protein_metrics = analyze_protein_network(protein_network, \"Human Protein Interaction Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protein_visualize",
   "metadata": {},
   "source": [
    "##### (4) Visualize protein network (subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protein_viz_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_protein_subgraph(G, center_node=None, radius=1, node_limit=100):\n",
    "    \"\"\"\n",
    "    Plot a subgraph of the protein network\n",
    "    \n",
    "    Parameters:\n",
    "    - G: full protein network\n",
    "    - center_node: node to center the subgraph on (if None, uses highest degree node)\n",
    "    - radius: how many hops away from center to include\n",
    "    - node_limit: maximum number of nodes to display\n",
    "    \"\"\"\n",
    "    # If no center node specified, use the node with highest degree\n",
    "    if center_node is None:\n",
    "        center_node = max(dict(G.degree()).items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    # Get ego network (nodes within radius hops)\n",
    "    if center_node in G:\n",
    "        subgraph_nodes = nx.ego_graph(G, center_node, radius=radius).nodes()\n",
    "        # Limit the number of nodes if too many\n",
    "        if len(subgraph_nodes) > node_limit:\n",
    "            # Keep only the top connected nodes\n",
    "            subgraph_temp = G.subgraph(subgraph_nodes)\n",
    "            top_nodes = sorted(subgraph_temp.degree(), key=lambda x: x[1], reverse=True)[:node_limit]\n",
    "            subgraph_nodes = [n[0] for n in top_nodes]\n",
    "        \n",
    "        subgraph = G.subgraph(subgraph_nodes)\n",
    "        \n",
    "        plt.figure(figsize=(12, 12))\n",
    "        pos = nx.spring_layout(subgraph, k=0.5, iterations=50)\n",
    "        \n",
    "        # Draw nodes\n",
    "        node_sizes = [300 if node == center_node else 100 for node in subgraph.nodes()]\n",
    "        node_colors = ['red' if node == center_node else 'lightblue' for node in subgraph.nodes()]\n",
    "        \n",
    "        nx.draw_networkx_nodes(subgraph, pos, node_size=node_sizes, node_color=node_colors, alpha=0.7)\n",
    "        nx.draw_networkx_edges(subgraph, pos, alpha=0.3, width=0.5)\n",
    "        \n",
    "        # Draw labels for center and high-degree nodes\n",
    "        labels = {}\n",
    "        for node in subgraph.nodes():\n",
    "            if node == center_node or subgraph.degree(node) > np.percentile([d for n, d in subgraph.degree()], 75):\n",
    "                # Simplify protein ID for readability\n",
    "                labels[node] = node.split('.')[-1][:10]\n",
    "        \n",
    "        nx.draw_networkx_labels(subgraph, pos, labels, font_size=6)\n",
    "        \n",
    "        plt.title(f\"Protein Interaction Subgraph\\nCenter: {center_node.split('.')[-1][:15]}...\\n\"\n",
    "                  f\"Nodes: {len(subgraph.nodes())}, Edges: {len(subgraph.edges())}\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Node {center_node} not found in graph\")\n",
    "\n",
    "# Plot subgraph centered on highest degree protein\n",
    "plot_protein_subgraph(protein_network, radius=1, node_limit=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protein_degree_dist",
   "metadata": {},
   "source": [
    "##### (5) Degree distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protein_degree_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze degree distribution\n",
    "degrees = [d for n, d in protein_network.degree()]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(degrees, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Protein Interaction Network: Degree Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Log-log plot (to check for scale-free properties)\n",
    "plt.subplot(1, 2, 2)\n",
    "degree_counts = pd.Series(degrees).value_counts().sort_index()\n",
    "plt.loglog(degree_counts.index, degree_counts.values, 'bo', alpha=0.6)\n",
    "plt.xlabel('Degree (log scale)')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.title('Protein Interaction Network: Degree Distribution (log-log)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDegree statistics:\")\n",
    "print(f\"Average degree: {sum(degrees)/len(degrees):.2f}\")\n",
    "print(f\"Maximum degree: {max(degrees)}\")\n",
    "print(f\"Minimum degree: {min(degrees)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990f267",
   "metadata": {},
   "source": [
    "### Statistics and centrality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebb428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edfeed8f",
   "metadata": {},
   "source": [
    "### Community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e41f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3383b86d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
